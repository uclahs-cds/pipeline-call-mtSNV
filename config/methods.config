import nextflow.util.SysHelper
includeConfig "${projectDir}/external/pipeline-Nextflow-config/config/methods/common_methods.config"
includeConfig "${projectDir}/external/pipeline-Nextflow-config/config/schema/schema.config"
includeConfig "${projectDir}/external/pipeline-Nextflow-config/config/bam/bam_parser.config"
includeConfig "${projectDir}/external/pipeline-Nextflow-config/config/retry/retry.config"

methods {

    get_id_from_bam = { bam_path ->
        def bam_header = bam_parser.parse_bam_header(bam_path)
        def sm_tags = bam_header['read_group'].collect{ it['SM'] }.unique()
        if (sm_tags.size() > 1) {
            throw new Exception("${bam_path} contains multiple samples! Please run pipeline with single sample BAMs.")
        }
        def sm_tag = methods.sanitize_uclahs_cds_id(sm_tags[0])
        return sm_tag
        }

    prepare_input = {
        // transform input into list format
        params.input_channel_list = []
        params.input.each {
            sample_type, sample ->
            def data_path = sample*.value[0]
            def entry_map = [
                'sample_type': sample_type,
                'data_path': data_path
                ]
            params.input_channel_list.add(entry_map)
            }
        // set sample mode
        switch (params.input_channel_list.size()) {
            case 0:
                error("   ### ERROR ###   No samples provided")
                break
            case 1:
                params.sample_mode = 'single'
                break
            case 2:
                params.sample_mode = 'paired'
                break
            }
        // create info string for log
        params.input_string = ''
        params.input.each {
            entry ->
            params.input_string <<= entry.key << ": " << entry*.value[0] << "\n\s\s\s\s\s\s\s\s"
            }
        params.input_string = params.input_string.toString().trim()
        }

    set_output_dir = {
        def tz = TimeZone.getTimeZone("UTC")
        def date = new Date().format("yyyyMMdd'T'HHmmss'Z'", tz)
        params.date = "${date}"

        params.sample_id = "null"
        params.output_dir_base = "${params.output_dir}/${manifest.name}-${manifest.version}/${-> params.sample_id}/mitoCaller-${params.mitocaller_version}/"
        params.nextflow_log_dir = "${-> params.output_dir_base}/log-${manifest.name}-${manifest.version}-${date}/"
        params.log_output_dir = "${-> params.nextflow_log_dir}process-log/"
        }


    set_pipeline_logs = {
        timeline.enabled = true
        timeline.file = "${params.nextflow_log_dir}nextflow-log/timeline.html"

        trace.enabled = true
        trace.file = "${params.nextflow_log_dir}nextflow-log/trace.txt"

        report.enabled = true
        report.file =  "${params.nextflow_log_dir}nextflow-log/report.html"
        }


    modify_base_allocations = {
        if (!(params.containsKey('base_resource_update') && params.base_resource_update)) {
            return
        }

        params.base_resource_update.each { resource, updates ->
            updates.each { processes, multiplier ->
                def processes_to_update = (custom_schema_types.is_string(processes)) ? [processes] : processes
                methods.update_base_resource_allocation(resource, multiplier, processes_to_update)
            }
        }
    }

    setup = {
        schema.load_custom_types("${projectDir}/external/pipeline-Nextflow-config/config/schema/custom_schema_types.config")
        schema.load_custom_types("${projectDir}/config/custom_schema_types.config")
        schema.validate()
        methods.set_resources_allocation()
        methods.modify_base_allocations()
        methods.setup_docker_cpus()
        retry.setup_retry()
        methods.prepare_input()
        methods.set_output_dir()
        methods.set_pipeline_logs()
        methods.set_env()
        }
    }



