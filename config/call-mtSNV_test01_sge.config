//Metadata
manifest {
    name = "call-mtSNV"
    author = "Takafumi Yamaguchi; Nextflowization by Alfredo Enrique Gonzalez "
    description = "Pipeline for calling mitochonrdial SNVs"
    version = "1.0"
}

// SGE or Slurm
sge_scheduler = false // true or false ; Set to true if run on SGE 

//Enabling Docker

docker {
    enabled = true
    sudo = false
    
    // Pass user's UID/GID and group IDs to Docker
    uid_and_gid = "-u \$(id -u):\$(id -g)"
    all_group_ids = "\$(for i in `id --real --groups`; do echo -n \"--group-add=\$i \"; done)"

    runOptions = "${uid_and_gid} ${all_group_ids}"
}



// Global default params, used in configs

params {
    // sample inputs
    input_csv = "/data/users/agonzalez/002_Nextflowization_mtSNV/02_Version_2.0/inputs/input_test01_sge.csv"

    // input/output locations
    output_dir = "/data/users/agonzalez/002_Nextflowization_mtSNV/02_Version_2.0/output/test_01/"
    temp_dir = "/scratch/"
    log_output_dir = "/data/users/agonzalez/002_Nextflowization_mtSNV/02_Version_2.0/output/test_01/logs/"
   

    // References
    reference_genome_hg38 = '/data/users/agonzalez/ref/hg38/genome.fa'
    mt_ref = '/data/users/tyamaguchi/docker/mt/mitochondria-ref/chrRSRS.fasta'
    suplemental_scripts = '/data/users/agonzalez/002_Nextflowization_mtSNV/02_Version_2.0/suplemental_scripts/'
    gmapdb = '/data/users/agonzalez/002_Nextflowization_mtSNV/01_Version_1.0/01_pipeline/SGE/output/gmapdb/'
    genome_fasta = '/data/users/agonzalez/002_Nextflowization_mtSNV/01_Version_1.0/01_pipeline/SGE/output/genome_fasta/'
                                                                                                          

    //Single or Paired?
    sample_mode = 'single' // 'single' or 'paired'

    save_intermediate_files = true
    cache_intermediate_pipeline_steps = true

    // resource configuraton for entire pipeline
    max_number_of_parallel_jobs = 1


}

// location of Nextflow temp directories  
workDir = "/scratch/"
NXF_WORK = "/scratch/"
NXF_TEMP = "/scratch/"
NXF_HOME = "/scratch/"


process {
    // monitor process jobs with local (not slurm) executor
    executor = "local"

    // total amount of resources avaible to the pipeline
    maxForks = params.max_number_of_parallel_jobs

    // echo stdout of each step to stdout of pipeline
    echo = true
    cache = params.cache_intermediate_pipeline_steps

}

// pipeline monitoring and metric files
timeline {
    enabled = true
    file = "${params.output_dir}/timeline.html"
}

trace {
    enabled = true
    file = "${params.output_dir}/trace.txt"
}

report {
    enabled = true
    file = "${params.output_dir}/report.html"
}
